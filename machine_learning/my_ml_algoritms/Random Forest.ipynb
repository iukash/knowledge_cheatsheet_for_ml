{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10160829",
   "metadata": {},
   "source": [
    "## Случайный лес (беггинг)\n",
    "\n",
    "Идея беггинга заключается в том чтобы построить композицию моделей с меньшим относительно одной модели разбросом. Построение композиции происходит за счет генерации бутстрепом выборки $\\widetilde X$ из всей имеющейся выборки $X$ (где $|\\widetilde X| = d$, размеру выборки) и построения модели $b(x)$ с помощью модели $\\mu$ на выборке $\\widetilde X$.\n",
    "$$ a(x) = \\frac{1}{N}\\sum_{n=1}^N b_n(x)$$ \n",
    "где $a(x)$ - композиция моделей.\n",
    "\n",
    "Для того чтобы понять принцип работы беггинга, разложим ошибку предсказания на компоненты\n",
    "$$L(\\mu) = \\mathbb E_{x, y}(y-\\mathbb E(y|x))^2 + \\mathbb E_x (\\mathbb E_x \\mu(X) - \\mathbb E(y|x))^2 + \\mathbb E_x \\mathbb E_X(\\mu(X) - \\mathbb E_x \\mu(X))^2 $$\n",
    "где \n",
    "* 1-я компонента в формуле - шумовая компонента: показывает насколько плох лучший из возможных алгоритмов\n",
    "* 2-я компонента - смещение (bias): показывает насколько в среднем мы в состоянии приблизить лучшую модель\n",
    "* 3-я компонента - разброс (variance): отклонение модели на данной выборке относительно средней модели\n",
    "\n",
    "Воздействовать на 1-ю компоненту мы не можем по определению, на 2-ю в случае беггинга не получится в силу того что смещение композиции $a(x)$ равно смещению любой из модели $b(x)$, т.е. не уменьшится от количества моделей и зависит от выбора базовой модели (необходимо выбирать базовую модель с низким смещением), а вот влияние на 3-ю разберем подробнее. Формула разброса выглядит следующим образом:\n",
    "$$variance(a(x)) = (\\frac{1}{N} \\mathbb E_x \\mathbb E_X (\\tilde \\mu (X) - \\mathbb E_X \\tilde \\mu (X))^2)(1) + (\\frac{N*(N-1)}{N^2} \\mathbb E_x \\mathbb E_X (\\tilde \\mu_1(X) - \\mathbb E_x \\tilde \\mu_1 )(\\tilde \\mu_2(X) - \\mathbb E_x \\tilde \\mu_2 ))(2)$$\n",
    "где \n",
    "* $\\tilde \\mu (X) - \\mathbb E_X \\tilde \\mu (X)$ - разброс одной модели\n",
    "* $\\mathbb E_x$ - перебор по всем объектам множества X\n",
    "* $\\mathbb E_X$ - перебор по всем подмножествам\n",
    "* $(\\tilde \\mu_1(X) - \\mathbb E_x \\tilde \\mu_1 )$ - ковариация моделей построенных бутсрепом\n",
    "\n",
    "Из формулы разброса делаем вывод что для минизации разброса необходимо:\n",
    "1) Максимально увеличить количество моделей (для уменьшения первой компоненты формулы)\n",
    "2) Ответы моделей должны быть как можно менее скоррелированы между собой (для уменьшения второй компоненты)\n",
    "\n",
    "Исходя из поставленных требований в целях снижения смещения выбираем глубокие деревья, а в целях снижения ковариации (помимо ее снижения от бутстрепа) изменяем алгоритм работы дерева (каждый раз при выборе лучшего предиката ограничить набор признаков classification $m = \\sqrt d$ regression $m = \\frac{d}{3}$). Полученный алгоритм и является случайным лесом (Random Forest).\n",
    "\n",
    "Одним из интересных свойств случайного леса является Out-of-bag оценка. Идея заклчается в том чтобы проводить оценку по объектам, которые не попали в обучающую выборку из-за бутсрепа.\n",
    "\n",
    "Слабые стороны данного алгоритма скорость работы (длительный процесс построения большого количества глубоких деревьев)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a1a86a",
   "metadata": {},
   "source": [
    "### Далее реализация метода"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4454694",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
